{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook compares the performance of an AutoGluon-generated model with both a normal PyTorch model and a Quantization-Aware Training (QAT) PyTorch model.\n",
    "It performs the following steps:\n",
    "1. Load the dataset (train, test, and validation sets).\n",
    "2. Load the AutoGluon predictor.\n",
    "3. Load the replicated normal PyTorch model and the QAT PyTorch model.\n",
    "4. Evaluate and compare the accuracy and log loss of all models.\n",
    "5. Compare the complexity (number of parameters) and size of all models.\n",
    "6. Visualize the results with plots.\n",
    "\n",
    "Make sure to update the paths to the models and dataset accordingly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/carloshh/tiny_model/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from autogluon.tabular import TabularPredictor, TabularDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths, update if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_path = '/path/to/your/predictor'  # Update this path as necessary\n",
    "data_dir = './datasets/CICIDS2017/balanced_binary/'  # Update this path as necessary\n",
    "normal_model_path = './path/to/save/normal_pytorch_model.pth'  # Update this path as necessary\n",
    "qat_model_path = './path/to/save/qat_pytorch_model.pth'  # Update this path as necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    train_data = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "    test_data = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
    "    val_data = pd.read_csv(os.path.join(data_dir, 'validation.csv'))\n",
    "    \n",
    "    # Drop the ID column\n",
    "    train_data = train_data.drop(columns=['ID'])\n",
    "    test_data = test_data.drop(columns=['ID'])\n",
    "    val_data = val_data.drop(columns=['ID'])\n",
    "    \n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_data['Label'] = label_encoder.fit_transform(train_data['Label'])\n",
    "    test_data['Label'] = label_encoder.transform(test_data['Label'])\n",
    "    val_data['Label'] = label_encoder.transform(val_data['Label'])\n",
    "    \n",
    "    return train_data, test_data, val_data, label_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, val_data, label_encoder = load_data(data_dir)\n",
    "\n",
    "# Convert to TabularDataset\n",
    "train_data_tab = TabularDataset(train_data)\n",
    "test_data_tab = TabularDataset(test_data)\n",
    "val_data_tab = TabularDataset(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Could not find version file at \"/path/to/your/predictor/version.txt\".\n",
      "This means that the predictor was fit in an AutoGluon version `<=0.3.1`.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/your/predictor/predictor.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load AutoGluon model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mTabularPredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictor_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load PyTorch model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAutoReplicatedNN\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
      "File \u001b[0;32m~/tiny_model/.venv/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:4399\u001b[0m, in \u001b[0;36mTabularPredictor.load\u001b[0;34m(cls, path, verbosity, require_version_match, require_py_version_match, check_packages)\u001b[0m\n\u001b[1;32m   4396\u001b[0m     version_saved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version_saved \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4399\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   4401\u001b[0m         version_saved \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39m_learner\u001b[38;5;241m.\u001b[39mversion\n",
      "File \u001b[0;32m~/tiny_model/.venv/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:4322\u001b[0m, in \u001b[0;36mTabularPredictor._load\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m   4317\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   4318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load\u001b[39m(\u001b[38;5;28mcls\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTabularPredictor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   4319\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4320\u001b[0m \u001b[38;5;124;03m    Inner load method, called in `load`.\u001b[39;00m\n\u001b[1;32m   4321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4322\u001b[0m     predictor: TabularPredictor \u001b[38;5;241m=\u001b[39m \u001b[43mload_pkl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor_file_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4323\u001b[0m     learner \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39m_learner_type\u001b[38;5;241m.\u001b[39mload(path)\n\u001b[1;32m   4324\u001b[0m     predictor\u001b[38;5;241m.\u001b[39m_set_post_fit_vars(learner\u001b[38;5;241m=\u001b[39mlearner)\n",
      "File \u001b[0;32m~/tiny_model/.venv/lib/python3.10/site-packages/autogluon/common/loaders/load_pkl.py:43\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, format, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m     compression_fn_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression_fn \u001b[38;5;129;01min\u001b[39;00m compression_fn_map:\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mcompression_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcompression_fn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopen\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidated_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompression_fn_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28mobject\u001b[39m \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(fin)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/your/predictor/predictor.pkl'"
     ]
    }
   ],
   "source": [
    "# Load AutoGluon model\n",
    "predictor = TabularPredictor.load(predictor_path)\n",
    "\n",
    "# Load PyTorch model\n",
    "class AutoReplicatedNN(nn.Module):\n",
    "    def __init__(self, architecture, input_feature_size):\n",
    "        super(AutoReplicatedNN, self).__init__()\n",
    "        layers = []\n",
    "        current_input_size = input_feature_size\n",
    "        for layer_type, layer_obj in architecture:\n",
    "            if layer_type == nn.BatchNorm1d:\n",
    "                layers.append(nn.BatchNorm1d(current_input_size))\n",
    "            elif layer_type == nn.Linear:\n",
    "                layers.append(nn.Linear(current_input_size, layer_obj.out_features))\n",
    "                current_input_size = layer_obj.out_features\n",
    "            elif layer_type == nn.ReLU:\n",
    "                layers.append(nn.ReLU())\n",
    "            elif layer_type == nn.Dropout:\n",
    "                layers.append(nn.Dropout(p=layer_obj.p))\n",
    "            elif layer_type == nn.Softmax:\n",
    "                layers.append(nn.Softmax(dim=layer_obj.dim))\n",
    "            else:\n",
    "                raise ValueError(f\"Unhandled layer type: {layer_type}\")\n",
    "        self.main_block = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.main_block(x)\n",
    "\n",
    "def get_model_architecture(predictor, input_feature_size):\n",
    "    best_model_name = predictor.get_model_best()\n",
    "    best_model = predictor._trainer.load_model(best_model_name)\n",
    "    \n",
    "    architecture = []\n",
    "    for name, layer in best_model.model.named_children():\n",
    "        if isinstance(layer, nn.Sequential):\n",
    "            for sub_layer in layer:\n",
    "                architecture.append((type(sub_layer), sub_layer))\n",
    "        else:\n",
    "            architecture.append((type(layer), layer))\n",
    "    \n",
    "    return architecture, best_model, input_feature_size\n",
    "\n",
    "# Determine the input feature size\n",
    "input_feature_size = train_data.drop(columns=['Label']).shape[1]\n",
    "\n",
    "# Get model architecture\n",
    "architecture, best_model, input_feature_size = get_model_architecture(predictor, input_feature_size)\n",
    "\n",
    "# Initialize the replicated models\n",
    "normal_model = AutoReplicatedNN(architecture, input_feature_size)\n",
    "qat_model = AutoReplicatedNN(architecture, input_feature_size)\n",
    "\n",
    "# Load the state dictionary of the normal PyTorch model\n",
    "normal_model.load_state_dict(torch.load(normal_model_path))\n",
    "\n",
    "# Load the state dictionary of the QAT PyTorch model\n",
    "qat_model.load_state_dict(torch.load(qat_model_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data\n",
    "X_test = test_data.drop(columns=['Label']).values\n",
    "y_test = test_data['Label'].values\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Evaluate AutoGluon model\n",
    "ag_predictions = predictor.predict_proba(test_data_tab)\n",
    "ag_accuracy = accuracy_score(y_test, ag_predictions.idxmax(axis=1))\n",
    "ag_loss = log_loss(y_test, ag_predictions)\n",
    "print(f'AutoGluon Model Accuracy: {ag_accuracy:.4f}')\n",
    "print(f'AutoGluon Model Log Loss: {ag_loss:.4f}')\n",
    "\n",
    "# Evaluate normal PyTorch model\n",
    "normal_model.eval()\n",
    "with torch.no_grad():\n",
    "    normal_outputs = normal_model(X_test_tensor)\n",
    "    normal_predictions = torch.argmax(normal_outputs, dim=1)\n",
    "    normal_accuracy = accuracy_score(y_test_tensor, normal_predictions)\n",
    "    normal_loss = log_loss(y_test, nn.Softmax(dim=1)(normal_outputs).numpy())\n",
    "print(f'Normal PyTorch Model Accuracy: {normal_accuracy:.4f}')\n",
    "print(f'Normal PyTorch Model Log Loss: {normal_loss:.4f}')\n",
    "\n",
    "# Evaluate QAT PyTorch model\n",
    "qat_model.eval()\n",
    "with torch.no_grad():\n",
    "    qat_outputs = qat_model(X_test_tensor)\n",
    "    qat_predictions = torch.argmax(qat_outputs, dim=1)\n",
    "    qat_accuracy = accuracy_score(y_test_tensor, qat_predictions)\n",
    "    qat_loss = log_loss(y_test, nn.Softmax(dim=1)(qat_outputs).numpy())\n",
    "print(f'QAT PyTorch Model Accuracy: {qat_accuracy:.4f}')\n",
    "print(f'QAT PyTorch Model Log Loss: {qat_loss:.4f}')\n",
    "\n",
    "# Compare model sizes\n",
    "ag_model_size = os.path.getsize(os.path.join(predictor.path, 'model.pkl'))\n",
    "normal_model_size = os.path.getsize(normal_model_path)\n",
    "qat_model_size = os.path.getsize(qat_model_path)\n",
    "print(f'AutoGluon Model Size: {ag_model_size / 1024:.2f} KB')\n",
    "print(f'Normal PyTorch Model Size: {normal_model_size / 1024:.2f} KB')\n",
    "print(f'QAT PyTorch Model Size: {qat_model_size / 1024:.2f} KB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Accuracy comparison\n",
    "axes[0, 0].bar(['AutoGluon', 'Normal PyTorch', 'QAT PyTorch'], [ag_accuracy, normal_accuracy, qat_accuracy], color=['blue', 'orange', 'green'])\n",
    "axes[0, 0].set_title('Model Accuracy')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "\n",
    "# Log Loss comparison\n",
    "axes[0, 1].bar(['AutoGluon', 'Normal PyTorch', 'QAT PyTorch'], [ag_loss, normal_loss, qat_loss], color=['blue', 'orange', 'green'])\n",
    "axes[0, 1].set_title('Model Log Loss')\n",
    "axes[0, 1].set_ylabel('Log Loss')\n",
    "\n",
    "# Model size comparison\n",
    "axes[1, 0].bar(['AutoGluon', 'Normal PyTorch', 'QAT PyTorch'], [ag_model_size / 1024, normal_model_size / 1024, qat_model_size / 1024], color=['blue', 'orange', 'green'])\n",
    "axes[1, 0].set_title('Model Size')\n",
    "axes[1, 0].set_ylabel('Size (KB)')\n",
    "\n",
    "# Complexity comparison (number of parameters)\n",
    "ag_params = sum(p.numel() for p in best_model.model.parameters())\n",
    "normal_params = sum(p.numel() for p in normal_model.parameters())\n",
    "qat_params = sum(p.numel() for p in qat_model.parameters())\n",
    "axes[1, 1].bar(['AutoGluon', 'Normal PyTorch', 'QAT PyTorch'], [ag_params, normal_params, qat_params], color=['blue', 'orange', 'green'])\n",
    "axes[1, 1].set_title('Model Complexity')\n",
    "axes[1, 1].set_ylabel('Number of Parameters')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
