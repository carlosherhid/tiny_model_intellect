{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook compares the performance of an AutoGluon-generated model with both a normal PyTorch model and a Quantization-Aware Training (QAT) PyTorch model.\n",
    "It performs the following steps:\n",
    "1. Load the dataset (train, test, and validation sets).\n",
    "2. Load the AutoGluon predictor.\n",
    "3. Load the replicated normal PyTorch model and the QAT PyTorch model.\n",
    "4. Evaluate and compare the accuracy and log loss of all models.\n",
    "5. Compare the complexity (number of parameters) and size of all models.\n",
    "6. Visualize the results with plots.\n",
    "\n",
    "Make sure to update the paths to the models and dataset accordingly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from autogluon.tabular import TabularPredictor, TabularDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.quantization import QuantStub, DeQuantStub, prepare_qat, convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths, update if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_path = './datasets/CICIDS2017/balanced_binary/automl_search'  # Update this path as necessary\n",
    "data_dir = './datasets/CICIDS2017/balanced_binary'  # Update this path as necessary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    train_data = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "    test_data = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
    "    val_data = pd.read_csv(os.path.join(data_dir, 'validation.csv'))\n",
    "    \n",
    "    # Drop the ID column\n",
    "    train_data = train_data.drop(columns=['ID'])\n",
    "    test_data = test_data.drop(columns=['ID'])\n",
    "    val_data = val_data.drop(columns=['ID'])\n",
    "    \n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_data['Label'] = label_encoder.fit_transform(train_data['Label'])\n",
    "    test_data['Label'] = label_encoder.transform(test_data['Label'])\n",
    "    val_data['Label'] = label_encoder.transform(val_data['Label'])\n",
    "    \n",
    "    return train_data, test_data, val_data\n",
    "\n",
    "def get_model_architecture(predictor, input_feature_size):\n",
    "    best_model_name = predictor.get_model_best()\n",
    "    best_model = predictor._trainer.load_model(best_model_name)\n",
    "    \n",
    "    architecture = []\n",
    "    for name, layer in best_model.model.named_children():\n",
    "        if isinstance(layer, nn.Sequential):\n",
    "            for sub_layer in layer:\n",
    "                architecture.append((type(sub_layer), sub_layer))\n",
    "        else:\n",
    "            architecture.append((type(layer), layer))\n",
    "    \n",
    "    return architecture, best_model, input_feature_size\n",
    "\n",
    "class AutoReplicatedNN(nn.Module):\n",
    "    def __init__(self, architecture, input_feature_size):\n",
    "        super(AutoReplicatedNN, self).__init__()\n",
    "        layers = []\n",
    "        current_input_size = input_feature_size\n",
    "        for layer_type, layer_obj in architecture:\n",
    "            if layer_type == nn.BatchNorm1d:\n",
    "                layers.append(nn.BatchNorm1d(current_input_size))\n",
    "            elif layer_type == nn.Linear:\n",
    "                layers.append(nn.Linear(current_input_size, layer_obj.out_features))\n",
    "                current_input_size = layer_obj.out_features\n",
    "            elif layer_type == nn.ReLU:\n",
    "                layers.append(nn.ReLU())\n",
    "            elif layer_type == nn.Dropout:\n",
    "                layers.append(nn.Dropout(p=layer_obj.p))\n",
    "            elif layer_type == nn.Softmax:\n",
    "                layers.append(nn.Softmax(dim=layer_obj.dim))\n",
    "            else:\n",
    "                raise ValueError(f\"Unhandled layer type: {layer_type}\")\n",
    "        self.main_block = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.main_block(x)\n",
    "\n",
    "class QATWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(QATWrapper, self).__init__()\n",
    "        self.quant = QuantStub()\n",
    "        self.model = model\n",
    "        self.dequant = DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.model(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "def evaluate_quantized_model(model, X_test_tensor, y_test_tensor):\n",
    "    model.eval()\n",
    "    X_test_tensor_quant = torch.quantize_per_tensor(X_test_tensor, scale=1.0, zero_point=0, dtype=torch.quint8)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor_quant.dequantize())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        accuracy = accuracy_score(y_test_tensor, predicted)\n",
    "    return accuracy\n",
    "def evaluate_model(model, X_test_tensor, y_test_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        accuracy = accuracy_score(y_test_tensor, predicted)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, val_data = load_data(data_dir)\n",
    "\n",
    "# Convert to TabularDataset\n",
    "#train_data_tab = TabularDataset(train_data)\n",
    "#test_data_tab = TabularDataset(test_data)\n",
    "#val_data_tab = TabularDataset(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Autogluon predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 1 mismatches between original and current metadata:\n",
      "\tINFO: AutoGluon Python micro version mismatch (original=3.10.14, current=3.10.12)\n"
     ]
    }
   ],
   "source": [
    "# Load AutoGluon model\n",
    "predictor = TabularPredictor.load(predictor_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2236582/3414897611.py:20: DeprecationWarning: `get_model_best` has been deprecated and will be removed in version 1.2. Please use `model_best` instead. This will raise an error in the future!\n",
      "  best_model_name = predictor.get_model_best()\n"
     ]
    }
   ],
   "source": [
    "input_feature_size = train_data.drop(columns=['Label']).shape[1]\n",
    "architecture, best_model, input_feature_size = get_model_architecture(predictor, input_feature_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.drop(columns=['Label']).values\n",
    "y_test = test_data['Label'].values\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading models and evaluating accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = {\n",
    "    \"AutoGluon\": predictor_path,\n",
    "    \"Normal PyTorch\": './datasets/CICIDS2017/balanced_binary/compressed_models/normal_pytorch_model.pth',  # Update with your normal model path\n",
    "    \"Pre-QAT PyTorch\": './datasets/CICIDS2017/balanced_binary/compressed_models/pre_qat_pytorch_model.pth',  # Update with your pre-QAT model path\n",
    "    \"QAT PyTorch\": './datasets/CICIDS2017/balanced_binary/compressed_models/qat_pytorch_model.pth'  # Update with your QAT model path\n",
    "}\n",
    "\n",
    "accuracies = {}\n",
    "\n",
    "# Evaluate AutoGluon model\n",
    "test_data_tab = TabularDataset(test_data)\n",
    "accuracies[\"AutoGluon\"] = predictor.evaluate(test_data_tab)['accuracy']\n",
    "\n",
    "# Evaluate Normal PyTorch model\n",
    "normal_model = AutoReplicatedNN(architecture, input_feature_size)\n",
    "normal_model.load_state_dict(torch.load(model_paths[\"Normal PyTorch\"]))\n",
    "accuracies[\"Normal PyTorch\"] = evaluate_model(normal_model, torch.tensor(test_data.drop(columns=['Label']).values, dtype=torch.float32), torch.tensor(test_data['Label'].values, dtype=torch.long))\n",
    "\n",
    "# Evaluate Pre-QAT PyTorch model\n",
    "pre_qat_model = AutoReplicatedNN(architecture, input_feature_size)\n",
    "pre_qat_model.load_state_dict(torch.load(model_paths[\"Pre-QAT PyTorch\"]))\n",
    "pre_qat_model.eval()\n",
    "accuracies[\"Pre-QAT PyTorch\"] = evaluate_model(pre_qat_model, X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Evaluate QAT PyTorch model\n",
    "qat_model_base = AutoReplicatedNN(architecture, input_feature_size)\n",
    "qat_model = QATWrapper(qat_model_base)\n",
    "qat_model.load_state_dict(torch.load(model_paths[\"QAT PyTorch\"]), strict=False)\n",
    "qat_model = convert(qat_model)\n",
    "qat_model.eval()\n",
    "accuracies[\"QAT PyTorch\"] = evaluate_quantized_model(qat_model, X_test_tensor, y_test_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracies:\n",
      "AutoGluon: 0.9925\n",
      "Normal PyTorch: 0.9788\n",
      "Pre-QAT PyTorch: 0.5000\n",
      "QAT PyTorch: 0.5000\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Accuracies:\")\n",
    "for model_name, accuracy in accuracies.items():\n",
    "    print(f\"{model_name}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
