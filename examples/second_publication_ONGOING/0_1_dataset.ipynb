{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation\n",
    "\n",
    "This notebook is used as a reference for the preparation of a dataset. From the given *CSV* files, we perform some processing operation to create the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import threadpoolctl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from intellect.io import recursive_find_file, dump, load\n",
    "from intellect.inspect import set_seed\n",
    "from intellect.dataset import balance_classes, load_dataframes, remove_constant_columns, format_dataframe_columns_names, format_dataframe_columns_values\n",
    "\n",
    "threadpoolctl.threadpool_limits(limits=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters. Note that these define the outcome of this notebook. Each parameter is explained in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# path to the CICIDS2017 and CICIDS2019 datasets\n",
    "DATASET_2017 = \"../../datasets/CICIDS2017/\"\n",
    "DATASET_2019 = \"../../datasets/CICIDS2019/\"\n",
    "\n",
    "# column marked as label in these datasets\n",
    "LABEL = 'Label'\n",
    "\n",
    "# labels to be considered as benign (class=0 in binary classification)\n",
    "BENIGN_LABELS = ['BENIGN']\n",
    "\n",
    "# columns to remove from datasets (session identifiers and non-commond features)\n",
    "EXCLUDED_COLUMNS = ['Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol', 'Timestamp', 'SimillarHTTP', 'Inbound']\n",
    "\n",
    "OUTPUT_DIR = \"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, load only the label column for both the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "files2019 = recursive_find_file(DATASET_2019, endswith_condition=\".csv\")\n",
    "frames_only_labels2019 = load_dataframes(files2019, only_labels_str=LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files2017 = recursive_find_file(DATASET_2017, endswith_condition=\".csv\")\n",
    "frames_only_labels2017 = load_dataframes(files2017, only_labels_str=LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep track of the original file and index (row in the file) to which each label comes from.\n",
    "Insert to each label the string \"2017\" or \"2019\" depending on their source dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for name, (dictionary) in zip([\"2017\", \"2019\"], [frames_only_labels2017, frames_only_labels2019]):\n",
    "    for k, v in dictionary.items():\n",
    "        v[\"File\"] = k\n",
    "        v[\"Indexes\"] = v.index.values\n",
    "        v[LABEL] += f\"-{name}\"\n",
    "        df.append(v)\n",
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print distribution of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "TFTP-2019                          20082580\n",
       "Syn-2019                            6473789\n",
       "MSSQL-2019                          5787453\n",
       "DrDoS_SNMP-2019                     5159870\n",
       "DrDoS_DNS-2019                      5071011\n",
       "DrDoS_MSSQL-2019                    4522492\n",
       "DrDoS_NetBIOS-2019                  4093279\n",
       "UDP-2019                            3867155\n",
       "NetBIOS-2019                        3657497\n",
       "DrDoS_UDP-2019                      3134645\n",
       "DrDoS_SSDP-2019                     2610611\n",
       "BENIGN-2017                         2273097\n",
       "DrDoS_LDAP-2019                     2179930\n",
       "LDAP-2019                           1915122\n",
       "DrDoS_NTP-2019                      1202642\n",
       "UDP-lag-2019                         366461\n",
       "DoS Hulk-2017                        231073\n",
       "Portmap-2019                         186960\n",
       "PortScan-2017                        158930\n",
       "DDoS-2017                            128027\n",
       "BENIGN-2019                          113828\n",
       "DoS GoldenEye-2017                    10293\n",
       "FTP-Patator-2017                       7938\n",
       "SSH-Patator-2017                       5897\n",
       "DoS slowloris-2017                     5796\n",
       "DoS Slowhttptest-2017                  5499\n",
       "Bot-2017                               1966\n",
       "UDPLag-2019                            1873\n",
       "Web Attack � Brute Force-2017          1507\n",
       "Web Attack � XSS-2017                   652\n",
       "WebDDoS-2019                            439\n",
       "Infiltration-2017                        36\n",
       "Web Attack � Sql Injection-2017          21\n",
       "Heartbleed-2017                          11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[LABEL].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance between benign and malicious classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "df_balanced = balance_classes(df, [\"BENIGN-2017\", \"BENIGN-2019\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "BENIGN-2017                        2273097\n",
       "DrDoS_NetBIOS-2019                  123421\n",
       "UDP-lag-2019                        123421\n",
       "UDP-2019                            123421\n",
       "TFTP-2019                           123421\n",
       "Portmap-2019                        123421\n",
       "PortScan-2017                       123421\n",
       "NetBIOS-2019                        123421\n",
       "MSSQL-2019                          123421\n",
       "LDAP-2019                           123421\n",
       "DrDoS_SSDP-2019                     123421\n",
       "DrDoS_UDP-2019                      123421\n",
       "DrDoS_NTP-2019                      123421\n",
       "DrDoS_MSSQL-2019                    123421\n",
       "DDoS-2017                           123421\n",
       "DrDoS_LDAP-2019                     123421\n",
       "DrDoS_DNS-2019                      123421\n",
       "DoS Hulk-2017                       123421\n",
       "DrDoS_SNMP-2019                     123420\n",
       "Syn-2019                            123420\n",
       "BENIGN-2019                         113828\n",
       "DoS GoldenEye-2017                   10293\n",
       "FTP-Patator-2017                      7938\n",
       "SSH-Patator-2017                      5897\n",
       "DoS slowloris-2017                    5796\n",
       "DoS Slowhttptest-2017                 5499\n",
       "Bot-2017                              1966\n",
       "UDPLag-2019                           1873\n",
       "Web Attack � Brute Force-2017         1507\n",
       "Web Attack � XSS-2017                  652\n",
       "WebDDoS-2019                           439\n",
       "Infiltration-2017                       36\n",
       "Web Attack � Sql Injection-2017         21\n",
       "Heartbleed-2017                         11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced[LABEL].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns that do not appear in both the two datasets, and remove the additionally specified ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = set(pd.read_csv(files2017[0], index_col=0, skipinitialspace=True, nrows=0).columns.tolist()).intersection(\n",
    "    pd.read_csv(files2019[0], index_col=0, skipinitialspace=True, nrows=0).columns.tolist())\n",
    "[cols.discard(x) for x in EXCLUDED_COLUMNS]\n",
    "cols = list(cols)\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load original samples from the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for x in files2019 + files2017:\n",
    "    tmp = dict.fromkeys((df_balanced[df_balanced['File'] == x]['Indexes'] + 1).tolist() + [0])\n",
    "    tmp_df = pd.read_csv(x, index_col=0, skipinitialspace=True, usecols=cols, skiprows=lambda x: x not in tmp)\n",
    "    final.append(tmp_df)\n",
    "final = pd.concat(final, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "BENIGN                        2386925\n",
       "DrDoS_DNS                      123421\n",
       "DrDoS_SSDP                     123421\n",
       "DDoS                           123421\n",
       "DoS Hulk                       123421\n",
       "MSSQL                          123421\n",
       "Portmap                        123421\n",
       "NetBIOS                        123421\n",
       "UDP                            123421\n",
       "DrDoS_NetBIOS                  123421\n",
       "LDAP                           123421\n",
       "DrDoS_UDP                      123421\n",
       "DrDoS_LDAP                     123421\n",
       "UDP-lag                        123421\n",
       "TFTP                           123421\n",
       "DrDoS_NTP                      123421\n",
       "PortScan                       123421\n",
       "DrDoS_MSSQL                    123421\n",
       "Syn                            123420\n",
       "DrDoS_SNMP                     123420\n",
       "DoS GoldenEye                   10293\n",
       "FTP-Patator                      7938\n",
       "SSH-Patator                      5897\n",
       "DoS slowloris                    5796\n",
       "DoS Slowhttptest                 5499\n",
       "Bot                              1966\n",
       "UDPLag                           1873\n",
       "Web Attack � Brute Force         1507\n",
       "Web Attack � XSS                  652\n",
       "WebDDoS                           439\n",
       "Infiltration                       36\n",
       "Web Attack � Sql Injection         21\n",
       "Heartbleed                         11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform all the possible features in numeric. This is useful in case the *read_csv* function was not able to correctly detect the data type when loading the *CSV*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = final.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting remaining categorical features (e.g., HTTP method, GET, POST) into numerical, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [col_name for col_name,\n",
    "        dtype in df_numeric.dtypes.items() if dtype == object and col_name not in (\"Label\", \"Source\")]\n",
    "if cat_columns:\n",
    "    print(\"Converting following categorical to numerical\", cat_columns)\n",
    "    df_numeric[cat_columns] = df_numeric[cat_columns].astype('category')\n",
    "    df_numeric[cat_columns] = df_numeric[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    df_numeric[cat_columns] = df_numeric[cat_columns].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing rows with missing values (e.g., NaN or Inf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before dropping NaN (4773850, 77)\n",
      "Resulting shape (4705419, 77)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape before dropping NaN\", df_numeric.shape)\n",
    "df_wo_nan = df_numeric.replace([np.inf, -np.inf], np.nan).dropna(axis=0, how=\"any\")\n",
    "print(\"Resulting shape\", df_wo_nan.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "BENIGN                        2384051\n",
       "DDoS                           123419\n",
       "PortScan                       123321\n",
       "DrDoS_SNMP                     123163\n",
       "DoS Hulk                       122924\n",
       "DrDoS_NTP                      122662\n",
       "DrDoS_UDP                      121819\n",
       "DrDoS_SSDP                     121421\n",
       "DrDoS_LDAP                     121251\n",
       "UDP                            120957\n",
       "LDAP                           120625\n",
       "DrDoS_MSSQL                    119987\n",
       "TFTP                           119953\n",
       "DrDoS_NetBIOS                  119620\n",
       "DrDoS_DNS                      119457\n",
       "MSSQL                          119114\n",
       "NetBIOS                        118664\n",
       "Portmap                        116987\n",
       "Syn                            113114\n",
       "UDP-lag                        110995\n",
       "DoS GoldenEye                   10293\n",
       "FTP-Patator                      7935\n",
       "SSH-Patator                      5897\n",
       "DoS slowloris                    5796\n",
       "DoS Slowhttptest                 5499\n",
       "Bot                              1956\n",
       "UDPLag                           1873\n",
       "Web Attack � Brute Force         1507\n",
       "Web Attack � XSS                  652\n",
       "WebDDoS                           439\n",
       "Infiltration                       36\n",
       "Web Attack � Sql Injection         21\n",
       "Heartbleed                         11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wo_nan[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing all the constant features among the selected dataset. These feature might result constant after the balancing of the samples, meaning that few samples with potentially different values for these features have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove constant removed the features {'Bwd Avg Bulk Rate', 'Bwd Avg Packets/Bulk', 'Bwd URG Flags', 'Fwd Avg Bulk Rate', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bytes/Bulk', 'Bwd PSH Flags', 'Bwd Avg Bytes/Bulk'}\n"
     ]
    }
   ],
   "source": [
    "prevs = set(df_wo_nan.columns.values)\n",
    "df_wo_const: pd.DataFrame = remove_constant_columns(df_wo_nan)\n",
    "print(\"Remove constant removed the features\", prevs - set(df_wo_const.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove identical features (cloned columns or same distribution). *Fwd Header Length.1* is an exact copy of *Fwd Header Length*, while the others present the same values of other columns in the dataset, hence only one is kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identical columns removed {'Subflow Fwd Packets', 'Fwd Header Length.1', 'Avg Fwd Segment Size', 'Subflow Bwd Packets'}\n"
     ]
    }
   ],
   "source": [
    "prevs = set(df_wo_const.columns.values)\n",
    "df_wo_dup = df_wo_const[df_wo_const.describe(include=\"all\").T.drop_duplicates().T.columns]\n",
    "print(\"Identical columns removed\", prevs - set(df_wo_dup.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format column and label names (remove extra white spaces, UNICODE characters if any, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formatted = format_dataframe_columns_values(format_dataframe_columns_names(df_wo_dup), \"Label\")\n",
    "df_formatted.index.name = \"ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(df_formatted, OUTPUT_DIR + \"dataset.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
