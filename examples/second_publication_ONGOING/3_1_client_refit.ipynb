{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Finetune to Client Traffic post Pruning-SubsetSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we investigate the potential effects of tha pruning and subset search achieved in the previous step. The aim is to verify whether it is possible to empower the lightweight model with the knwoledge of the oracle model, obtained in the initial Federated Learning training phase.\n",
    "\n",
    "The main problem is that by pruning and removing features from the network traffic to fit specific deployment scenarios, the organization might have obtained a model with worse performance than the previous one. \n",
    "Moreover, if it is willing to specialize that model to its specific traffic categories, how does the model behave against the other previously seen attacks?\n",
    "Is it possible to preserve the knwoledge? Will it face catastrophic forgetting? Can you postpone catastrophic forgetting somehow?\n",
    "\n",
    "We will analyse different learning algorithms that the organization can adopt during this finetune process and measure the loss in the global knowledge of the model with respect to all the attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import threadpoolctl\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "from intellect.model.torch.model import Mlp\n",
    "from intellect.model.torch.pruning import globally_unstructured_connections_l1\n",
    "from intellect.io import load, dump, create_dir\n",
    "from intellect.inspect import set_seed\n",
    "from intellect.scoring import compute_metric_percategory\n",
    "from intellect.dataset import (Dataset, ContinuouLearningAlgorithm, FeatureAvailability,\n",
    "    portions_from_data, indexes_for_oracle_learning, InputForLearn)\n",
    "\n",
    "threadpoolctl.threadpool_limits(limits=1);\n",
    "mpl.rcParams['figure.dpi']= 70\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameters and scenarios to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "# dataset and useful directories\n",
    "DATASET = \"./dataset_shrinked.h5\"\n",
    "TRAIN_MODEL = \"train_output/oracle.pt\"\n",
    "RANK_DIR = \"rank_prune_output/\"\n",
    "OUTPUT_DIR = \"refit_output/\"\n",
    "\n",
    "# client categories, benign labels and dataset portions. Should be equal to the previous notebook.\n",
    "CLIENT_CATEGORIES = [\"BENIGN\", \"DDoS\"]\n",
    "BENIGN_LABELS = [\"BENIGN\"]\n",
    "DATASET_PORTIONS = (0.6, 0.1, 0.1, 0.2)\n",
    "\n",
    "# target feature subset size for which this notebook is performing the tests.\n",
    "TARGET_SUBSET_RATIOS = (0.1, 0.3, 0.5, 0.8)\n",
    "\n",
    "# all possible tested scenarios:\n",
    "# o_to_o:  oracle to oracle scenario, the student/client model is a copy of the oracle model.\n",
    "# o_to_po: oracle to pruned oracle scenario, where the student/client model is a pruned version of the oracle.\n",
    "# o_to_eo: oracle to edge oracle scenario, where the student/client is a copy of the oracle model, but it is provided\n",
    "#               with only a limited set of features\n",
    "# o_to_ec: oracle to edge client scenario, where the student/client is a pruned version of the oracle model AND it is provided\n",
    "#               with only a limited set of features\n",
    "SCENARIOS = {\n",
    "    \"o_to_o\": {\"availability\": (FeatureAvailability.bilateral,), \"learn_input\": (InputForLearn.client,)},\n",
    "    \"o_to_po\": {\"availability\": (FeatureAvailability.bilateral,), \"learn_input\": (InputForLearn.client,),},\n",
    "    \"o_to_eo\": {\"availability\": (FeatureAvailability.none, FeatureAvailability.oracle,), \"learn_input\": (InputForLearn.client, InputForLearn.oracle, InputForLearn.mixed)},\n",
    "    \"o_to_ec\": {\"availability\": (FeatureAvailability.none, FeatureAvailability.oracle,), \"learn_input\": (InputForLearn.client, InputForLearn.oracle, InputForLearn.mixed)},}\n",
    "\n",
    "# knowledge distillation hyperaparameters space\n",
    "KD_HYPERPARAMS = {\n",
    "    \"alpha\": (1,),#(1, 0.9),\n",
    "    \"temperature\": (14,)}#(20, 14, 7, 4)}\n",
    "\n",
    "# common hyperparameters\n",
    "COMMON_PARAMETERS = {\n",
    "    \"max_epochs\": (20,),#(100, ),\n",
    "    \"epochs_wo_improve\": (100,),\n",
    "    \"batch_size\": (64, ),\n",
    "    \"algorithm\": (ContinuouLearningAlgorithm.ground_truth, ContinuouLearningAlgorithm.ground_inferred, ContinuouLearningAlgorithm.knowledge_distillation)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset, keep the validation portion to measure loss of knowledge, and finetune portions that will act as the new re-train portion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    set_seed()\n",
    "    return portions_from_data(DATASET, normalize=True, benign_labels=BENIGN_LABELS, ratios=DATASET_PORTIONS)\n",
    "_, validation, finetune, _ = get_dataset()\n",
    "cols = [\"Global\"] + CLIENT_CATEGORIES + [v for v in finetune._y.value_counts().sort_values(ascending=False).index.values if v not in CLIENT_CATEGORIES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_cache = {}\n",
    "student_cache = {}\n",
    "\n",
    "def run_test(save_prefix: str, finetune_ds: Dataset, features_available=None,\n",
    "             skip=False, prune_ratio=None, availability=None, **kwargs):\n",
    "    if skip is True and os.path.isfile(f\"{save_prefix}.csv\"):\n",
    "        return\n",
    "    if features_available is None:\n",
    "        features_available = []\n",
    "    set_seed()\n",
    "    oracle_net= Mlp.load(TRAIN_MODEL)\n",
    "    student_net = Mlp.load(TRAIN_MODEL)\n",
    "    \n",
    "    if prune_ratio is not None:\n",
    "        student_net = globally_unstructured_connections_l1(student_net, prune_ratio)\n",
    "\n",
    "    idx, idx_oracle = indexes_for_oracle_learning(finetune_ds, features_available, availability)\n",
    "    \n",
    "    key_oracle = (hash(finetune_ds), hash(str(idx_oracle)))\n",
    "    key_student = (hash(finetune_ds), hash(str(idx)), hash(prune_ratio))\n",
    "\n",
    "    if key_oracle not in oracle_cache:\n",
    "        oracle_tmp_val = validation.clone()\n",
    "        oracle_tmp_test = finetune_ds.clone()\n",
    "        oracle_tmp_val.X.iloc[:, idx_oracle] = 0.\n",
    "        oracle_tmp_test.X.iloc[:, idx_oracle] = 0.\n",
    "        oracle_cache[key_oracle] = {\n",
    "            \"validation\": compute_metric_percategory(oracle_tmp_val.y, oracle_net.predict(oracle_tmp_val.X), oracle_tmp_val._y, scorer=accuracy_score),\n",
    "            \"finetune\": compute_metric_percategory(oracle_tmp_test.y, oracle_net.predict(oracle_tmp_test.X), oracle_tmp_test._y, scorer=accuracy_score)}\n",
    "\n",
    "    tmp_val = validation.clone()\n",
    "    tmp_test = finetune_ds.clone()\n",
    "    tmp_val.X.iloc[:, idx] = 0.\n",
    "    tmp_test.X.iloc[:, idx] = 0.\n",
    "\n",
    "    if key_student not in student_cache:\n",
    "        student_cache[key_student] = {\n",
    "            \"validation\": compute_metric_percategory(tmp_val.y, student_net.predict(tmp_val.X), tmp_val._y, scorer=accuracy_score),\n",
    "            \"finetune\": compute_metric_percategory(tmp_test.y, student_net.predict(tmp_test.X), tmp_test._y, scorer=accuracy_score)}\n",
    "    \n",
    "    hs, m = student_net.fit(finetune_ds, oracle=oracle_net, idx_active_features=idx, idx_active_features_oracle=idx_oracle,\n",
    "                            monitori_ds=tmp_val, **kwargs)\n",
    "    dump(m, f\"{save_prefix}_monitor.csv\")\n",
    "    dump(hs, f\"{save_prefix}_history.csv\")\n",
    "    \n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    df.loc[\"Validation Before\"] = student_cache[key_student][\"validation\"]\n",
    "    df.loc[\"Validation After\"] = compute_metric_percategory(tmp_val.y, student_net.predict(tmp_val.X), tmp_val._y, scorer=accuracy_score)\n",
    "    df.loc[\"Finetune Before\"] = student_cache[key_student][\"finetune\"]\n",
    "    df.loc[\"Finetune After\"] = compute_metric_percategory(tmp_test.y, student_net.predict(tmp_test.X), tmp_test._y, scorer=accuracy_score)\n",
    "    df.loc[\"Oracle Validation\"] = oracle_cache[key_oracle][\"validation\"]\n",
    "    df.loc[\"Oracle Finetune\"] = oracle_cache[key_oracle][\"finetune\"]\n",
    "    dump(df, f\"{save_prefix}.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scenario(scenario_dict, dirname, categories=None, features_available=None, skip=False, **kwargs):\n",
    "    if categories is None:\n",
    "        categories = []\n",
    "    if not os.path.isdir(OUTPUT_DIR + dirname) or skip is False:\n",
    "        create_dir(OUTPUT_DIR + dirname)\n",
    "    tmp = finetune\n",
    "    if categories:\n",
    "        set_seed()\n",
    "        tmp = tmp.filter_categories(categories).balance_categories()\n",
    "    params = deepcopy(scenario_dict)\n",
    "    params.update(COMMON_PARAMETERS)\n",
    "    combinations = [dict(zip(params.keys(), v)) for v in itertools.product(*params.values())]\n",
    "    for c in combinations:\n",
    "        if c[\"availability\"].value == FeatureAvailability.none.value and c[\"learn_input\"].value != InputForLearn.client.value:\n",
    "            continue\n",
    "        add_params = [c]\n",
    "        if features_available is None or not len(features_available):\n",
    "            c[\"availability\"] = FeatureAvailability.bilateral\n",
    "        if c[\"algorithm\"].name == ContinuouLearningAlgorithm.knowledge_distillation.name:\n",
    "            add_params = [{**c, \"learn_kwargs\": dict(zip(KD_HYPERPARAMS.keys(), v))} for v in itertools.product(*KD_HYPERPARAMS.values())]\n",
    "        print(\"----Running\", len(add_params), \"combinations for\", c[\"algorithm\"].name, \"and\", c[\"availability\"], \"and\", c[\"learn_input\"])\n",
    "        for p in add_params:\n",
    "            name = OUTPUT_DIR + dirname + \"-\".join(f\"{k}_{v.name if hasattr(v, 'name') else v}\" for k,v in p.items())\n",
    "            run_test(name, tmp, **kwargs, features_available=features_available, skip=skip, **p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Refit Algoithms for different use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oracle to Oracle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_scenario(SCENARIOS[\"o_to_o\"], f\"o_to_o_few_c/\", categories=CLIENT_CATEGORIES, features_available=None, prune_ratio=None, skip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oracle to Pruned Oracle. Select highest prune ratio with worst performance degradation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = load(RANK_DIR + \"traffic_few_c_pruning_ratios_only.csv\", index_col=0)\n",
    "col = res[\"Prune Ratio\"]\n",
    "row = res.iloc[col[col == col.max()].index[-1]]\n",
    "print(\"Highest pruning ratio to preserve the accuracy is\", row[\"Prune Ratio\"], f\"(Accuracy of {row['Accuracy']})\")\n",
    "run_scenario(SCENARIOS[\"o_to_po\"], f\"o_to_po_few_c/\", categories=CLIENT_CATEGORIES,\n",
    "             features_available=None, prune_ratio=row[\"Prune Ratio\"], skip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oracle to Edge Oracle. Select the worst performant accepted feature subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in TARGET_SUBSET_RATIOS:\n",
    "    res = load(RANK_DIR + f\"rank_few_c_traffic_few_c_subsets_features_for_subsetsize_{s}.csv\", index_col=0)\n",
    "    worst_row = res.iloc[-1]\n",
    "    subset = worst_row[~worst_row.index.isin([\"Accuracy\"]) & worst_row.notnull()].index.values\n",
    "    print(\"For a subset size of ratio\", s, \"the worst performant subset identified achieved an Accuracy of\", worst_row[\"Accuracy\"])\n",
    "    run_scenario(SCENARIOS[\"o_to_eo\"], f\"o_to_eo_few_c_subset_{s}/\", categories=CLIENT_CATEGORIES,\n",
    "                 features_available=subset, prune_ratio=None, skip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oracle to Edge Client. Select highest prune ratio with worst performance degradation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in TARGET_SUBSET_RATIOS:\n",
    "    res = load(RANK_DIR + f\"rank_few_c_traffic_few_c_combo_pruned_models_subsets_features_for_subsetsize_{s}.csv\", index_col=0)\n",
    "    col = res[\"Prune Ratio\"]\n",
    "    idx = col[col == col.max()].index.values[-1]\n",
    "    worst_row = res.loc[idx]\n",
    "    prune_ratio = worst_row[\"Prune Ratio\"]\n",
    "    subset = worst_row[~worst_row.index.isin([\"Accuracy\", \"Prune Ratio\"]) & worst_row.notnull()].index.values\n",
    "    print(\"For a subset size of ratio\", s, \"the worst performant subset identified has a maximum accepted prune ratio of\",\n",
    "          prune_ratio, f\"(Accuracy of {worst_row['Accuracy']})\")\n",
    "    run_scenario(SCENARIOS[\"o_to_ec\"], f\"o_to_ec_few_c_subset_{s}/\", categories=CLIENT_CATEGORIES,\n",
    "                 features_available=subset, prune_ratio=prune_ratio, skip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If interested in any further test, there are all those with the model whose feature ranking has been performed on all traffic categories, and also those where the stochastic search is performed before the pruning (expect the oracle to be better than pruned model always)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
