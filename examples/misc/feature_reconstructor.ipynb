{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of different Feature Reconstruction mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add needed imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import threadpoolctl\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "import matplotlib as mpl\n",
    "\n",
    "from intellect.model.torch.model import MlpEncoder\n",
    "from intellect.model.sklearn.model import EnhancedMlpRegressor\n",
    "from intellect.io import dump, create_dir\n",
    "from intellect.inspect import set_seed\n",
    "from intellect.dataset import ProblemType, portions_from_data\n",
    "\n",
    "threadpoolctl.threadpool_limits(limits=2);\n",
    "mpl.rcParams['figure.dpi']= 70\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "N_HIDDEN_LAYERS = 4\n",
    "N_HIDDEN_UNITS = 128\n",
    "\n",
    "# training parameters\n",
    "BATCH_SIZE = 256\n",
    "MAX_EPOCHS = 100\n",
    "EPOCHS_WO_IMPROVE = 10\n",
    "\n",
    "VALIDATION_SIZE = 0.2\n",
    "BENIGN_LABELS = [\"BENIGN\"]\n",
    "DATASET_PORTIONS = (0.6, 0.1, 0.1, 0.2)\n",
    "KEPT_FEATURES_RATIO = 0.5\n",
    "\n",
    "# traffic categories that only this client (organization) has\n",
    "CLIENT_CATEGORIES = [\"BENIGN\", \"DDoS\"]\n",
    "\n",
    "DATASET = \"../second_publication_ONGOING/dataset_shrinked.h5\"\n",
    "OUTPUT_DIR = \"./reconstruct_output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "_, _, finetune, test = portions_from_data(DATASET, benign_labels=BENIGN_LABELS, ptype=ProblemType.BINARY, ratios=DATASET_PORTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "filtered_features = np.random.choice(finetune.features, round(finetune.n_features*KEPT_FEATURES_RATIO), replace=False)\n",
    "finetune_client = finetune.filter_categories(CLIENT_CATEGORIES).balance_categories()\n",
    "test_client = test.filter_categories(CLIENT_CATEGORIES).balance_categories()\n",
    "idxes = test_client.filter_features(filtered_features, get_removal_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_regressor():\n",
    "    set_seed()\n",
    "    finetune_client_filtered = finetune_client.filter_features(filtered_features, default=0)\n",
    "    test_client_filtered = test_client.filter_features(filtered_features, default=0.)\n",
    "    p = RandomForestRegressor()\n",
    "    p.fit(finetune_client_filtered.X, finetune_client.X)\n",
    "    dump(p, OUTPUT_DIR + \"sklearn_rfr.pkl\")\n",
    "    return mean_squared_error(test_client.X, p.predict(test_client_filtered.X))\n",
    "\n",
    "def linear_regression():\n",
    "    set_seed()\n",
    "    finetune_client_filtered = finetune_client.filter_features(filtered_features, default=0)\n",
    "    test_client_filtered = test_client.filter_features(filtered_features, default=0.)\n",
    "    p = LinearRegression()\n",
    "    p.fit(finetune_client_filtered.X, finetune_client.X)\n",
    "    dump(p, OUTPUT_DIR + \"sklearn_lr.pkl\")\n",
    "    return mean_squared_error(test_client.X, p.predict(test_client_filtered.X))\n",
    "\n",
    "def sklearn_autoencoder():\n",
    "    set_seed()\n",
    "    finetune_client_filtered = finetune_client.filter_features(filtered_features, default=0)\n",
    "    test_client_filtered = test_client.filter_features(filtered_features, default=0.)\n",
    "    p = EnhancedMlpRegressor(hidden_layer_sizes=(N_HIDDEN_UNITS,)*N_HIDDEN_LAYERS, max_iter=MAX_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                             validation_fraction=VALIDATION_SIZE, warm_start=True, shuffle=True)\n",
    "    p.fit(finetune_client_filtered.X, finetune_client.X)\n",
    "    dump(p, OUTPUT_DIR + \"sklearn_ae.pkl\")\n",
    "    return mean_squared_error(test_client.X, p.predict(test_client_filtered.X))\n",
    "\n",
    "def torch_autoencoder():\n",
    "    set_seed()\n",
    "    finetune_client_filtered = finetune_client.filter_features(filtered_features, default=0)\n",
    "    test_client_filtered = test_client.filter_features(filtered_features, default=0.)\n",
    "    \n",
    "    finetune_client_filtered.y = finetune_client.X\n",
    "\n",
    "    p: MlpEncoder = MlpEncoder(finetune_client.features, N_HIDDEN_LAYERS)\n",
    "    history = p.fit(finetune_client_filtered, validation_dataset=VALIDATION_SIZE, batch_size=BATCH_SIZE, max_epochs=MAX_EPOCHS, epochs_wo_improve=EPOCHS_WO_IMPROVE,\n",
    "          metric=mean_squared_error, higher_better=False, shuffle=True);\n",
    "    p.save(OUTPUT_DIR + \"torch_autoencoder\")\n",
    "    history_df = pd.DataFrame(history)\n",
    "    dump(history_df, OUTPUT_DIR + \"torch_autoencoder_history.csv\")\n",
    "    return mean_squared_error(test_client.X, p.predict(test_client_filtered.X))\n",
    "\n",
    "def iterative_imputer():\n",
    "    set_seed()\n",
    "    finetune_client_filtered = finetune_client.filter_features(filtered_features, default=np.nan)\n",
    "    test_client_filtered = test_client.filter_features(filtered_features, default=np.nan)\n",
    "    p = IterativeImputer()\n",
    "    p.fit(finetune_client_filtered.X, finetune_client.X)\n",
    "    dump(p, OUTPUT_DIR + \"sklearn_ii.pkl\")\n",
    "    out = test_client_filtered.X.to_numpy()\n",
    "    out[:, idxes] = p.transform(test_client_filtered.X)\n",
    "    return mean_squared_error(test_client.X, out)\n",
    "\n",
    "def knn_imputer():\n",
    "    set_seed()\n",
    "    finetune_client_filtered = finetune_client.filter_features(filtered_features, default=np.nan)\n",
    "    test_client_filtered = test_client.filter_features(filtered_features, default=np.nan)\n",
    "    p = KNNImputer()\n",
    "    p.fit(finetune_client_filtered.X, finetune_client.X)\n",
    "    dump(p, OUTPUT_DIR + \"sklearn_knni.pkl\")\n",
    "    out = test_client_filtered.X.to_numpy()\n",
    "    out[:, idxes] = p.transform(test_client_filtered.X)\n",
    "    return mean_squared_error(test_client.X, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80306894820406.47"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_imputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80306894820406.47"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterative_imputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41656774906540.85"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_regressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.450642799241474e+23"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488401872233145.75"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_autoencoder()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
